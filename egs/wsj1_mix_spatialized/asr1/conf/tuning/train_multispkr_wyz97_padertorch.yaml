# network architecture
model-module: espnet.nets.pytorch_backend.e2e_asr_mix:E2E
# encoder related
etype: vggblstmp
elayers-sd: 0   # number of speaker differentiate encoder layers
elayers: 3      # number of recognition encoder layers
eunits: 1024
eprojs: 1024
subsample: 1_2_2_1_1  # skip every n frame from input to nth layers
# decoder related
dlayers: 1
dunits: 300
# attention related
atype: location
adim: 320
awin: 5
aheads: 4
aconv-chans: 10
aconv-filts: 100

# hybrid CTC/attention
mtlalpha: 0.2

# label smoothing
lsm-type: unigram
lsm-weight: 0.05

# minibatch related
batch-size: 10
#batch-size: 8
maxlen-in: 500  # if input length  > maxlen-in, batchsize is automatically reduced
maxlen-out: 150 # if output length > maxlen-out, batchsize is automatically reduced

# optimization related
sortagrad: 0 # Feed samples from shortest to longest ; -1: enabled for all epochs, 0: disabled, other: enabled for 'other' epochs
opt: adadelta
accum-grad: 1
grad-clip: 5
patience: 3
epochs: 15
dropout-rate: 0.0

# scheduled sampling option
sampling-probability: 0.0

# CMVN
stats-file: fbank/tr_spatialized_all/cmvn.ark
apply-uttmvn: false

# reporting
#report-wer: True

# frontend related
btype: blstm
use-frontend: True
use-beamforming-first: False
# beamforming
use-beamformer: True
blayers: 3
bnmask: 6
bunits: 600
bprojs: 600
beamformer-type: wmpdr
ref-channel: 0
# WPE
use-wpe: True
use-dnn-mask-for-wpe: True
wpe-taps: 5 #1
